# Assignment 4 – GAN-based Density Estimation on NO₂ Data

## Dataset
India Air Quality Data (Kaggle) — NO₂ column extracted for analysis.

## Data Transformation
Raw NO₂ values (`x`) are transformed into a target signal `z` using a sinusoidal function seeded by the student registration number `r = 102303491`:

```
z = a_r * sin(b_r * x)
```

where `a_r = 0.5 * (r % 7)` and `b_r = 0.3 * (r % 5 + 1)`.

## Model: GAN (Generative Adversarial Network)

A lightweight GAN is trained to learn the distribution of `z`:

| Component | Architecture |
|-----------|-------------|
| **Generator** | Linear(1→32) → ReLU → Linear(32→32) → ReLU → Linear(32→1) |
| **Discriminator** | Linear(1→32) → ReLU → Linear(32→1) → Sigmoid |

- **Optimizer:** Adam (lr = 0.001) for both networks
- **Loss:** Binary Cross-Entropy (BCELoss)
- **Training:** 2000 epochs, batch size 64
- The Generator takes random Gaussian noise as input and learns to produce samples that mimic the distribution of `z`.

## Graph: GAN-Generated Distribution and KDE PDF

The single plot overlays two things:

1. **Histogram (bars)** — shows the empirical distribution of 2000 samples generated by the trained Generator after training. This reflects what distribution the GAN has learned to approximate.

2. **KDE curve (line)** — a Gaussian Kernel Density Estimate (bandwidth = 0.3) fitted on the GAN-generated samples. It provides a smooth continuous approximation of the learned probability density.

Together, the histogram and KDE curve reveal how well the GAN has captured the underlying distribution of the transformed NO₂ signal `z = a_r * sin(b_r * x)`. Since `z` is a bounded sinusoidal transform, the learned distribution is expected to be multimodal or concentrated in a limited range, unlike a simple Gaussian.
